Hello from rank 2 of 4 on holygpu8a19405.rc.fas.harvard.edu where there are 1 allocated GPUs per node. | (CUDA_VISIBLE_DEVICES=0)
Hello from rank 3 of 4 on holygpu8a19601.rc.fas.harvard.edu where there are 1 allocated GPUs per node. | (CUDA_VISIBLE_DEVICES=0)
Hello from rank 1 of 4 on holygpu8a19305.rc.fas.harvard.edu where there are 1 allocated GPUs per node. | (CUDA_VISIBLE_DEVICES=0)
Hello from rank 0 of 4 on holygpu8a19301.rc.fas.harvard.edu where there are 1 allocated GPUs per node. | (CUDA_VISIBLE_DEVICES=0)
Using GPU0 on Machine holygpu8a19405 (Rank 2)
Using GPU0 on Machine holygpu8a19305 (Rank 1)
Group initialized? True
Using GPU0 on Machine holygpu8a19301 (Rank 0)
Using GPU0 on Machine holygpu8a19601 (Rank 3)
Loaded pre-trained model.
Loaded pre-trained model.
Loaded pre-trained model.
Loaded pre-trained model.
[GPU0] Epoch 0 | Batchsize: 32 | Steps: 24
Epoch 1/10 starting...
[GPU1] Epoch 0 | Batchsize: 32 | Steps: 24
[GPU3] Epoch 0 | Batchsize: 32 | Steps: 24
[GPU2] Epoch 0 | Batchsize: 32 | Steps: 24
Rank 0 | Epoch Loss: 1.7101463079452515
Rank 1 | Epoch Loss: 1.730041265487671
Rank 2 | Epoch Loss: 1.7302829027175903
Rank 3 | Epoch Loss: 1.7197974920272827
Epoch [1/10], Total Loss: 6.8903
[GPU2] Epoch 1 | Batchsize: 32 | Steps: 24
[GPU3] Epoch 1 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 1 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 1 | Batchsize: 32 | Steps: 24
Epoch 2/10 starting...
Rank 0 | Epoch Loss: 1.2625678777694702
Rank 2 | Epoch Loss: 1.2579615116119385
Rank 3 | Epoch Loss: 1.2848747968673706
Rank 1 | Epoch Loss: 1.2437050342559814
Epoch [2/10], Total Loss: 5.0491
[GPU3] Epoch 2 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 2 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 2 | Batchsize: 32 | Steps: 24
Epoch 3/10 starting...
[GPU2] Epoch 2 | Batchsize: 32 | Steps: 24
Rank 0 | Epoch Loss: 1.2572022676467896
Rank 3 | Epoch Loss: 1.232862949371338
Rank 1 | Epoch Loss: 1.2359569072723389
Rank 2 | Epoch Loss: 1.2316311597824097
Epoch [3/10], Total Loss: 4.9577
[GPU3] Epoch 3 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 3 | Batchsize: 32 | Steps: 24
Epoch 4/10 starting...
[GPU1] Epoch 3 | Batchsize: 32 | Steps: 24
[GPU2] Epoch 3 | Batchsize: 32 | Steps: 24
Rank 3 | Epoch Loss: 1.2406872510910034
Rank 1 | Epoch Loss: 1.2167781591415405
Rank 2 | Epoch Loss: 1.2390930652618408
Rank 0 | Epoch Loss: 1.228803277015686
Epoch [4/10], Total Loss: 4.9254
[GPU3] Epoch 4 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 4 | Batchsize: 32 | Steps: 24
Epoch 5/10 starting...
[GPU2] Epoch 4 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 4 | Batchsize: 32 | Steps: 24
Rank 3 | Epoch Loss: 1.210697889328003
Rank 1 | Epoch Loss: 1.1715866327285767
Rank 2 | Epoch Loss: 1.1860822439193726
Rank 0 | Epoch Loss: 1.2006378173828125
Epoch [5/10], Total Loss: 4.7690
[GPU3] Epoch 5 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 5 | Batchsize: 32 | Steps: 24
Epoch 6/10 starting...
[GPU1] Epoch 5 | Batchsize: 32 | Steps: 24
[GPU2] Epoch 5 | Batchsize: 32 | Steps: 24
Rank 3 | Epoch Loss: 1.1623862981796265
Rank 2 | Epoch Loss: 1.1488299369812012
Rank 0 | Epoch Loss: 1.1605029106140137
Rank 1 | Epoch Loss: 1.1410484313964844
Epoch [6/10], Total Loss: 4.6128
[GPU0] Epoch 6 | Batchsize: 32 | Steps: 24
Epoch 7/10 starting...
[GPU3] Epoch 6 | Batchsize: 32 | Steps: 24
[GPU2] Epoch 6 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 6 | Batchsize: 32 | Steps: 24
Rank 2 | Epoch Loss: 1.124473214149475
Rank 0 | Epoch Loss: 1.125983476638794
Rank 1 | Epoch Loss: 1.1115074157714844
Rank 3 | Epoch Loss: 1.107239842414856
Epoch [7/10], Total Loss: 4.4692
[GPU3] Epoch 7 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 7 | Batchsize: 32 | Steps: 24
Epoch 8/10 starting...
[GPU2] Epoch 7 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 7 | Batchsize: 32 | Steps: 24
Rank 2 | Epoch Loss: 1.075217366218567
Rank 3 | Epoch Loss: 1.0914137363433838
Rank 0 | Epoch Loss: 1.1103414297103882
Rank 1 | Epoch Loss: 1.0888421535491943
Epoch [8/10], Total Loss: 4.3658
[GPU2] Epoch 8 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 8 | Batchsize: 32 | Steps: 24
Epoch 9/10 starting...
[GPU3] Epoch 8 | Batchsize: 32 | Steps: 24
[GPU1] Epoch 8 | Batchsize: 32 | Steps: 24
Rank 2 | Epoch Loss: 1.0434808731079102
Rank 3 | Epoch Loss: 1.1047500371932983
Rank 0 | Epoch Loss: 1.0903023481369019
Rank 1 | Epoch Loss: 1.0616748332977295
Epoch [9/10], Total Loss: 4.3002
[GPU1] Epoch 9 | Batchsize: 32 | Steps: 24
[GPU3] Epoch 9 | Batchsize: 32 | Steps: 24
[GPU0] Epoch 9 | Batchsize: 32 | Steps: 24
Epoch 10/10 starting...
[GPU2] Epoch 9 | Batchsize: 32 | Steps: 24
Rank 3 | Epoch Loss: 0.999616265296936
Rank 2 | Epoch Loss: 0.9732171297073364
Rank 0 | Epoch Loss: 0.9989439249038696
Rank 1 | Epoch Loss: 1.016116976737976
Epoch [10/10], Total Loss: 3.9879
